# Default configuration for miniwdl runner, organized into sections & options within each section.
#
# miniwdl loads configuration options in the following priority order:
# 1. command-line arguments
# 2. environment variables MINIWDL__SECTION__KEY (uppercased with double-underscores)
# 3. custom configuration file (mutually exclusive):
#    a) file named on command-line --cfg
#    b) file named by environment variable MINIWDL_CFG
#    c) miniwdl.cfg in XDG_CONFIG_HOME & XDG_CONFIG_DIRS
# 4. WDL/runtime/config_templates/default.cfg


[scheduler]
# Size of thread pools for task and subworkflow calls. 0 = default to multiprocessing.cpu_count().
# Bounds how many tasks the runner can consider scheduling concurrently. Actual concurrency may be
# less due to CPU/memory resource availability. Too high a setting may overload miniwdl process. -@
call_concurrency = 0


[docker_swarm]
# Docker Swarm Mode is the default container backend. It's included with every docker installation,
# but disabled by default. The following option allows miniwdl to automatically initialize the local
# host as a one-node swarm if needed, by performing
#     docker swarm init --listen-addr 127.0.0.1 --advertise-addr 127.0.0.1
# This is is typically helpful for single-node use, but should be disabled if a preexisting swarm
# is to be used.
auto_init = true


[file_io]
# During startup, require the run directory and input files to reside somewhere within this root
# directory. This constraint is needed in cluster deployments relying on a shared mount. It can
# also be useful on a single node to prevent accidental consumption of a small boot/home volume,
# by confining workflow operations to some spacious scratch/data mount.
root = /
# Populate task working directory with writable copies of the input files, instead of mounting them
# in situ & read-only. Needed if tasks want to write/move/rename input files, but costs time and
# disk space. --copy-input-files
copy_input_files = false
# Each succeeded run directory has an "output_links/" folder containing (by default) a symbolic
# link to each output file in its original working location. If output_hardlinks is true, then
# output_links/ is populated with hardlinks instead of symlinks. Beware the potential confusion
# arising from files with multiple hardlinks! See also [task_runtime] delete_work, below.
output_hardlinks = false


[task_runtime]
# Effective maximum values of runtime.cpu and runtime.memory (bytes), which evaluated values are
# rounded down to. 0 = detect host resources, -1 = do not apply a limit.
# --runtime-cpu-max, --runtime-memory-max
# Warning: tasks may deadlock if these are set higher than actual provision-able resources.
cpu_max = 0
memory_max = 0
# Defaults which each task's runtime{} section will be merged into. --runtime-defaults
defaults = {
        "docker": "ubuntu:18.04"
    }
# Run the command script as the invoking user's uid:gid instead of usually running as root. More
# secure, but interferes with commands that assume root access e.g. apt-get. --as-me
as_user = false
# Delete task working directory upon completion. The task container's working directory is a
# bind-mounted host directory, so files written into it are left behind after the container is torn
# down. If tasks write large non-output files into their working directory (instead of $TMPDIR as
# they should), then it can be useful to delete them automatically.
# Values:
#   false   = never delete (default)
#   success = delete working directories of succeeded tasks
#   failure =            "                  failed tasks
#   always  =            "                  both succeeded and failed tasks
# The "success" and "always" settings require [file_io] output_hardlinks, above, to be true;
# otherwise, output files would be deleted too. Input/output JSON, logs, and stdout/stderr are
# always retained in the task run directory (above the container working directory).
delete_work = false


[download_cache]
# When a File input is supplied with a URI to be downloaded, store the downloaded file in a certain
# directory where it can later be found and reused for the same input URI.
put = false
# Enable retrieval of File input URIs from the local cache
get = false
# Base directory for local download cache
dir = /tmp/miniwdl_download_cache
# Remove URI query strings for cache key/lookup purposes. By default, downloads from URIs with
# query strings are never cached (neither put nor get).
ignore_query = false
# To be eligible for caching (in addition to above options), a URI must (i) match at least one glob
# pattern in enable_patterns, AND (ii) not match any disable_patterns.
enable_patterns = ["*"]
disable_patterns = ["*.php", "*.aspx"]


[plugins]
# Control which plugins are used. Plugins are installed using the Python entry points convention,
#   https://packaging.python.org/specifications/entry-points/
# Furthermore for a plugin to be used, its "object reference" must (i) match at least one glob
# pattern in enable_patterns, AND (ii) not match any disable_patterns.
enable_patterns = ["*"]
disable_patterns = ["miniwdl_task_omnibus_example:*"]
